{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "333ae546d607a744",
   "metadata": {},
   "source": [
    "# Workshop: Building an Information Retrieval System for Podcast Episodes\n",
    "\n",
    "## Objective:\n",
    "Create an Information Retrieval (IR) system that processes a dataset of podcast transcripts and, given a query, returns the episodes where the host and guest discuss the query topic. Use TF-IDF and BERT for vector space representation and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a934919d95ac2de",
   "metadata": {},
   "source": [
    "## Instructions:\n",
    "\n",
    "* Follow the steps outlined above to implement the IR system.\n",
    "* Run the provided code snippets to understand how each part of the system works.\n",
    "* Test the system with various queries to observe the results from both TF-IDF and BERT representations.\n",
    "* Compare and analyze the results. Discuss the pros and cons of each method.\n",
    "* Document your findings and any improvements you make to the system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a04253d",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries\n",
    "Import necessary libraries for data handling, text processing, and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "637a6429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Karen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Necessary libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ea6096",
   "metadata": {},
   "source": [
    "### Step 2: Load the Dataset\n",
    "\n",
    "Load the dataset of podcast transcripts.\n",
    "\n",
    "Find the dataset in: https://www.kaggle.com/datasets/rajneesh231/lex-fridman-podcast-transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98718132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'guest', 'title', 'text'], dtype='object')\n",
      "0    As part of MIT course 6S099, Artificial Genera...\n",
      "1    As part of MIT course 6S099 on artificial gene...\n",
      "2    You've studied the human mind, cognition, lang...\n",
      "3    What difference between biological neural netw...\n",
      "4    The following is a conversation with Vladimir ...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "podcast_df = pd.read_csv('../WEEK11/archive/podcastdata_dataset.csv')\n",
    "# Mostrar los nombres de las columnas\n",
    "print(podcast_df.columns)\n",
    "# Extract main information in this case is the title and text\n",
    "titles = podcast_df['title']\n",
    "text = podcast_df['text']  \n",
    "\n",
    "# View texxt\n",
    "print(text.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c564482a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Karen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Karen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Karen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary resources from NLTK for preprocessing\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77293a8",
   "metadata": {},
   "source": [
    "### Step 3: Text Preprocessing\n",
    "\n",
    "You know what to do ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdc708eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    part mit course artificial general intelligenc...\n",
      "1    part mit course artificial general intelligenc...\n",
      "2    studied human mind cognition language vision e...\n",
      "3    difference biological neural networks artifici...\n",
      "4    following conversation vladimir vapnik co inve...\n",
      "Name: processed_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # convert lowercase\n",
    "    text = text.lower()\n",
    "    # remove special carathers and numbers\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\d+', ' ', text)\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Join tokens into a single chain\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing  to text\n",
    "podcast_df['processed_text'] = podcast_df['text'].apply(preprocess_text)\n",
    "\n",
    "# Show some processed texts\n",
    "print(podcast_df['processed_text'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fe859f",
   "metadata": {},
   "source": [
    "###  Step 4: Vector Space Representation - TF-IDF\n",
    "\n",
    "Create TF-IDF vector representations of the transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db0b0305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TF-IDF matrix: (319, 47172)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Inicializar el vectorizador TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Ajustar y transformar las transcripciones procesadas\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(podcast_df['processed_text'])\n",
    "\n",
    "# Mostrar la forma de la matriz TF-IDF\n",
    "print(\"Shape of TF-IDF matrix:\", tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6402736b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<319x47172 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 728207 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d8c5ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.42.3)\n",
      "Requirement already satisfied: torch in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.13.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.13.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5338985",
   "metadata": {},
   "source": [
    "### Step 5: Vector Space Representation - BERT\n",
    "\n",
    "Create BERT vector representations of the transcripts using a pre-trained BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8d02a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of BERT embeddings: (768,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cargar el tokenizer y el modelo de BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Función para obtener las representaciones BERT\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "# Aplicar la función de embeddings BERT a las transcripciones procesadas\n",
    "podcast_df['bert_embeddings'] = podcast_df['processed_text'].apply(get_bert_embeddings)\n",
    "\n",
    "# Mostrar la forma de las representaciones BERT\n",
    "print(\"Shape of BERT embeddings:\", podcast_df['bert_embeddings'].iloc[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892930db",
   "metadata": {},
   "source": [
    "### Step 6: Query Processing\n",
    "\n",
    "Define a function to process the query and compute similarity scores using both TF-IDF and BERT embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15558a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para procesar la consulta\n",
    "def process_query(query, podcast_df, tfidf_vectorizer, tfidf_matrix):\n",
    "    # Preprocesar la consulta\n",
    "    query_processed = preprocess_text(query)\n",
    "\n",
    "    # Vectorizar la consulta utilizando TF-IDF\n",
    "    query_tfidf = tfidf_vectorizer.transform([query_processed])\n",
    "    \n",
    "    # Calcular la similitud de coseno para TF-IDF\n",
    "    tfidf_similarities = cosine_similarity(query_tfidf, tfidf_matrix).flatten()\n",
    "\n",
    "    # Vectorizar la consulta utilizando BERT\n",
    "    query_bert_embedding = get_bert_embeddings(query_processed).reshape(1, -1)\n",
    "    \n",
    "    # Calcular la similitud de coseno para BERT\n",
    "    bert_embeddings = np.vstack(podcast_df['bert_embeddings'].values)\n",
    "    bert_similarities = cosine_similarity(query_bert_embedding, bert_embeddings).flatten()\n",
    "\n",
    "    # Crear un DataFrame con los resultados\n",
    "    results_df = podcast_df.copy()\n",
    "    results_df['tfidf_similarity'] = tfidf_similarities\n",
    "    results_df['bert_similarity'] = bert_similarities\n",
    "\n",
    "    # Ordenar los resultados por la similitud más alta\n",
    "    results_df = results_df.sort_values(by=['tfidf_similarity', 'bert_similarity'], ascending=False)\n",
    "\n",
    "    return results_df[['title', 'tfidf_similarity', 'bert_similarity', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "540326b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query is: artificial\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tfidf_similarity</th>\n",
       "      <th>bert_similarity</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI in the Age of Reason</td>\n",
       "      <td>0.146613</td>\n",
       "      <td>0.155800</td>\n",
       "      <td>You've studied the human mind, cognition, lang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Square, Cryptocurrency, and Artificial Intelli...</td>\n",
       "      <td>0.074839</td>\n",
       "      <td>0.129934</td>\n",
       "      <td>The following is a conversation with Jack Dors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>0.072252</td>\n",
       "      <td>0.136753</td>\n",
       "      <td>What difference between biological neural netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Brains, Minds, and Machines</td>\n",
       "      <td>0.059004</td>\n",
       "      <td>0.142168</td>\n",
       "      <td>The following is a conversation with Tommaso P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Google</td>\n",
       "      <td>0.052326</td>\n",
       "      <td>0.138043</td>\n",
       "      <td>The following is a conversation with Eric Schm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  tfidf_similarity  \\\n",
       "2                             AI in the Age of Reason          0.146613   \n",
       "91  Square, Cryptocurrency, and Artificial Intelli...          0.074839   \n",
       "3                                       Deep Learning          0.072252   \n",
       "12                        Brains, Minds, and Machines          0.059004   \n",
       "7                                              Google          0.052326   \n",
       "\n",
       "    bert_similarity                                               text  \n",
       "2          0.155800  You've studied the human mind, cognition, lang...  \n",
       "91         0.129934  The following is a conversation with Jack Dors...  \n",
       "3          0.136753  What difference between biological neural netw...  \n",
       "12         0.142168  The following is a conversation with Tommaso P...  \n",
       "7          0.138043  The following is a conversation with Eric Schm...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solicitar la entrada del usuario para la consulta\n",
    "query = input(\"Ingrese su consulta: \")\n",
    "\n",
    "# Procesar la consulta del usuario\n",
    "results = process_query(query, podcast_df, tfidf_vectorizer, tfidf_matrix)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Query is:\",query)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f22d139",
   "metadata": {},
   "source": [
    "### Step 7: Retrieve and Compare Results\n",
    "\n",
    "Define a function to retrieve the top results based on similarity scores for both TF-IDF and BERT representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f68203a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query is: artificial\n",
      "\n",
      "Top TF-IDF Results:\n",
      "Title: AI in the Age of Reason\n",
      "TF-IDF Similarity: 0.14661302183592007\n",
      "Transcript Excerpt: You've studied the human mind, cognition, language, vision, evolution, psychology, from child to adult, from the level of individual to the level of our entire civilization. So I feel like I can start...\n",
      "\n",
      "\n",
      "Title: Square, Cryptocurrency, and Artificial Intelligence\n",
      "TF-IDF Similarity: 0.07483942890201313\n",
      "Transcript Excerpt: The following is a conversation with Jack Dorsey, co founder and CEO of Twitter and founder and CEO of Square. Given the happenings at the time related to Twitter leadership and the very limited time ...\n",
      "\n",
      "\n",
      "Title: Deep Learning\n",
      "TF-IDF Similarity: 0.07225237743107563\n",
      "Transcript Excerpt: What difference between biological neural networks and artificial neural networks is most mysterious, captivating, and profound for you? First of all, there's so much we don't know about biological ne...\n",
      "\n",
      "\n",
      "Title: Brains, Minds, and Machines\n",
      "TF-IDF Similarity: 0.0590036633676748\n",
      "Transcript Excerpt: The following is a conversation with Tommaso Poggio. He's a professor at MIT and is a director of the Center for Brains, Minds, and Machines. Cited over 100,000 times, his work has had a profound impa...\n",
      "\n",
      "\n",
      "Title: Google\n",
      "TF-IDF Similarity: 0.05232631142936892\n",
      "Transcript Excerpt: The following is a conversation with Eric Schmidt. He was the CEO of Google for 10 years and a chairman for six more, guiding the company through an incredible period of growth and a series of world c...\n",
      "\n",
      "\n",
      "\n",
      "Top BERT Results:\n",
      "Title: Biology of Disease\n",
      "BERT Similarity: 0.16301864385604858\n",
      "Transcript Excerpt: The following is a conversation with Manolis Kellis, his third time on the podcast. He is a professor at MIT and head of the MIT Computational Biology Group. This time we went deep on the science, bio...\n",
      "\n",
      "\n",
      "Title: Generative Adversarial Networks (GANs)\n",
      "BERT Similarity: 0.16215333342552185\n",
      "Transcript Excerpt: The following is a conversation with Ian Goodfellow. He's the author of the popular textbook on deep learning simply titled Deep Learning. He coined the term of Generative Adversarial Networks, otherw...\n",
      "\n",
      "\n",
      "Title: Flying Robots\n",
      "BERT Similarity: 0.1599254161119461\n",
      "Transcript Excerpt: The following is a conversation with Vijay Kumar. He's one of the top roboticists in the world, a professor at the University of Pennsylvania, a dean of pen engineering, former director of Grasp Lab, ...\n",
      "\n",
      "\n",
      "Title: Concepts, Analogies, Common Sense & Future of AI\n",
      "BERT Similarity: 0.159059077501297\n",
      "Transcript Excerpt: The following is a conversation with Melanie Mitchell. She's a professor of computer science at Portland State University and an external professor at Santa Fe Institute. She has worked on and written...\n",
      "\n",
      "\n",
      "Title: Reinforcement Learning, Planning, and Robotics\n",
      "BERT Similarity: 0.158212810754776\n",
      "Transcript Excerpt: The following is a conversation with Leslie Kaelbling. She is a roboticist and professor at MIT. She is recognized for her work in reinforcement learning, planning, robot navigation, and several other...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Función para recuperar y comparar los mejores resultados\n",
    "def retrieve_and_compare_results(query, podcast_df, tfidf_vectorizer, tfidf_matrix, top_n=5):\n",
    "    # Procesar la consulta\n",
    "    results_df = process_query(query, podcast_df, tfidf_vectorizer, tfidf_matrix)\n",
    "\n",
    "    # Ordenar los resultados por similitud de TF-IDF y recuperar los top N\n",
    "    top_tfidf_results = results_df.sort_values(by='tfidf_similarity', ascending=False).head(top_n)\n",
    "\n",
    "    # Ordenar los resultados por similitud de BERT y recuperar los top N\n",
    "    top_bert_results = results_df.sort_values(by='bert_similarity', ascending=False).head(top_n)\n",
    "\n",
    "    return top_tfidf_results, top_bert_results\n",
    "\n",
    "# Recuperar y comparar los resultados principales utilizando la consulta del usuario\n",
    "top_tfidf_results, top_bert_results = retrieve_and_compare_results(query, podcast_df, tfidf_vectorizer, tfidf_matrix, top_n=5)\n",
    "\n",
    "print(\"Query is:\",query)\n",
    "# Mostrar los resultados principales para TF-IDF\n",
    "print(\"\\nTop TF-IDF Results:\")\n",
    "for idx, row in top_tfidf_results.iterrows():\n",
    "    print(f\"Title: {row['title']}\")\n",
    "    print(f\"TF-IDF Similarity: {row['tfidf_similarity']}\")\n",
    "    print(f\"Transcript Excerpt: {row['text'][:200]}...\")  # Mostrar los primeros 200 caracteres de la transcripción\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Mostrar los resultados principales para BERT\n",
    "print(\"\\nTop BERT Results:\")\n",
    "for idx, row in top_bert_results.iterrows():\n",
    "    print(f\"Title: {row['title']}\")\n",
    "    print(f\"BERT Similarity: {row['bert_similarity']}\")\n",
    "    print(f\"Transcript Excerpt: {row['text'][:200]}...\")  # Mostrar los primeros 200 caracteres de la transcripción\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401d723b",
   "metadata": {},
   "source": [
    "### Step 8: Test the IR System\n",
    "\n",
    "Test the system with a sample query.\n",
    "\n",
    "Retrieve and display the top results using both TF-IDF and BERT representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81492a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query test is: artificial intelligence\n",
      "\n",
      "Top TF-IDF Results:\n",
      "Title: AI in the Age of Reason\n",
      "TF-IDF Similarity: 0.21138929368299314\n",
      "Transcript Excerpt: You've studied the human mind, cognition, language, vision, evolution, psychology, from child to adult, from the level of individual to the level of our entire civilization. So I feel like I can start...\n",
      "\n",
      "\n",
      "Title: Concepts, Analogies, Common Sense & Future of AI\n",
      "TF-IDF Similarity: 0.1700409854657989\n",
      "Transcript Excerpt: The following is a conversation with Melanie Mitchell. She's a professor of computer science at Portland State University and an external professor at Santa Fe Institute. She has worked on and written...\n",
      "\n",
      "\n",
      "Title: Measures of Intelligence\n",
      "TF-IDF Similarity: 0.15418131660687703\n",
      "Transcript Excerpt: The following is a conversation with Francois Chollet, his second time on the podcast. He's both a world class engineer and a philosopher in the realm of deep learning and artificial intelligence. Thi...\n",
      "\n",
      "\n",
      "Title: Keras, Deep Learning, and the Progress of AI\n",
      "TF-IDF Similarity: 0.14732215946575677\n",
      "Transcript Excerpt: The following is a conversation with Francois Chollet. He's the creator of Keras, which is an open source deep learning library that is designed to enable fast, user friendly experimentation with deep...\n",
      "\n",
      "\n",
      "Title: IQ Tests, Human Intelligence, and Group Differences\n",
      "TF-IDF Similarity: 0.14197287307367779\n",
      "Transcript Excerpt: Let me ask you to this question, whether it's bell curve or any research on race differences, can that be used to increase the amount of racism in the world, can that be used to increase the amount of...\n",
      "\n",
      "\n",
      "\n",
      "Top BERT Results:\n",
      "Title: Concepts, Analogies, Common Sense & Future of AI\n",
      "BERT Similarity: 0.23527444899082184\n",
      "Transcript Excerpt: The following is a conversation with Melanie Mitchell. She's a professor of computer science at Portland State University and an external professor at Santa Fe Institute. She has worked on and written...\n",
      "\n",
      "\n",
      "Title: Computational Biology of Coronavirus\n",
      "BERT Similarity: 0.23447737097740173\n",
      "Transcript Excerpt: The following is a conversation with Dmitry Korkin. He's a professor of bioinformatics and computational biology at WPI, Worcester Polytechnic Institute, where he specializes in bioinformatics of comp...\n",
      "\n",
      "\n",
      "Title: Neuroevolution and Evolutionary Computation\n",
      "BERT Similarity: 0.23431426286697388\n",
      "Transcript Excerpt: The following is a conversation with Risto Michaelainen, a computer scientist at University of Texas at Austin and Associate Vice President of Evolutionary Artificial Intelligence at Cognizant. He spe...\n",
      "\n",
      "\n",
      "Title: AI Superpowers – China and Silicon Valley\n",
      "BERT Similarity: 0.2289339303970337\n",
      "Transcript Excerpt: The following is a conversation with Kai Fu Lee. He's the chairman and CEO of Cinovation Ventures that manages a $2 billion dual currency investment fund with a focus on developing the next generation...\n",
      "\n",
      "\n",
      "Title: Keras, Deep Learning, and the Progress of AI\n",
      "BERT Similarity: 0.22756193578243256\n",
      "Transcript Excerpt: The following is a conversation with Francois Chollet. He's the creator of Keras, which is an open source deep learning library that is designed to enable fast, user friendly experimentation with deep...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir la consulta de prueba\n",
    "test_query = \"artificial intelligence\"\n",
    "\n",
    "# Recuperar y comparar los resultados principales utilizando la consulta de prueba\n",
    "top_tfidf_results, top_bert_results = retrieve_and_compare_results(test_query, podcast_df, tfidf_vectorizer, tfidf_matrix, top_n=5)\n",
    "\n",
    "print(\"Query test is:\",test_query)\n",
    "# Mostrar los resultados principales para TF-IDF\n",
    "print(\"\\nTop TF-IDF Results:\")\n",
    "for idx, row in top_tfidf_results.iterrows():\n",
    "    print(f\"Title: {row['title']}\")\n",
    "    print(f\"TF-IDF Similarity: {row['tfidf_similarity']}\")\n",
    "    print(f\"Transcript Excerpt: {row['text'][:200]}...\")  # Mostrar los primeros 200 caracteres de la transcripción\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Mostrar los resultados principales para BERT\n",
    "print(\"\\nTop BERT Results:\")\n",
    "for idx, row in top_bert_results.iterrows():\n",
    "    print(f\"Title: {row['title']}\")\n",
    "    print(f\"BERT Similarity: {row['bert_similarity']}\")\n",
    "    print(f\"Transcript Excerpt: {row['text'][:200]}...\")  # Mostrar los primeros 200 caracteres de la transcripción\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff10b1e1",
   "metadata": {},
   "source": [
    "### Step 9: Compare Results\n",
    "\n",
    "Analyze and compare the results obtained from TF-IDF and BERT representations.\n",
    "\n",
    "Discuss the differences, strengths, and weaknesses of each method based on the retrieval results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc912bfa",
   "metadata": {},
   "source": [
    "TF-IDF \n",
    "\n",
    "Ventaja: Los resultados suelen ser relevantes cuando las palabras clave de la consulta aparecen exactamente en el texto.\n",
    "Desventaja: Puede incluir resultados menos relevantes si las palabras clave son comunes en diferentes contextos.\n",
    "\n",
    "BERT\n",
    "\n",
    "Ventaja: Captura mejor el contexto y la semántica, proporcionando resultados más precisos y relevantes.\n",
    "Desventaja: Los resultados pueden variar y ser menos predecibles, pero suelen tener una comprensión más profunda del tema.\n",
    "\n",
    "\n",
    "Eficiencia Computacional\n",
    "\n",
    "\n",
    "TF-IDF: Es más rápido y eficiente computacionalmente. Adecuado para sistemas con recursos limitados.\n",
    "\n",
    "BERT: Requiere más recursos de procesamiento y memoria, pero ofrece una mayor precisión en la recuperación de información.\n",
    "\n",
    "Análisis de resultados\n",
    "\n",
    "TF-IDF: No tiene en cuenta el contexto de las palabras. Por ejemplo, la consulta \"inteligencia artificial\" puede coincidir con cualquier mención de esas palabras, sin importar el contexto.\n",
    "\n",
    "BERT: Entiende el contexto y puede identificar sinónimos y frases relacionadas. Por ejemplo, \"inteligencia artificial\" puede coincidir con discusiones sobre \"AI\" y \"machine learning\" de manera más precisa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
