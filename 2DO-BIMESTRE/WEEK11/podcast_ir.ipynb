{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "333ae546d607a744",
   "metadata": {},
   "source": [
    "# Workshop: Building an Information Retrieval System for Podcast Episodes\n",
    "\n",
    "## Objective:\n",
    "Create an Information Retrieval (IR) system that processes a dataset of podcast transcripts and, given a query, returns the episodes where the host and guest discuss the query topic. Use TF-IDF and BERT for vector space representation and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a934919d95ac2de",
   "metadata": {},
   "source": [
    "## Instructions:\n",
    "\n",
    "* Follow the steps outlined above to implement the IR system.\n",
    "* Run the provided code snippets to understand how each part of the system works.\n",
    "* Test the system with various queries to observe the results from both TF-IDF and BERT representations.\n",
    "* Compare and analyze the results. Discuss the pros and cons of each method.\n",
    "* Document your findings and any improvements you make to the system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a04253d",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries\n",
    "Import necessary libraries for data handling, text processing, and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "637a6429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ea6096",
   "metadata": {},
   "source": [
    "### Step 2: Load the Dataset\n",
    "\n",
    "Load the dataset of podcast transcripts.\n",
    "\n",
    "Find the dataset in: https://www.kaggle.com/datasets/rajneesh231/lex-fridman-podcast-transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98718132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'guest', 'title', 'text'], dtype='object')\n",
      "0    As part of MIT course 6S099, Artificial Genera...\n",
      "1    As part of MIT course 6S099 on artificial gene...\n",
      "2    You've studied the human mind, cognition, lang...\n",
      "3    What difference between biological neural netw...\n",
      "4    The following is a conversation with Vladimir ...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "podcast_df = pd.read_csv('../WEEK11/archive/podcastdata_dataset.csv')\n",
    "# Mostrar los nombres de las columnas\n",
    "print(podcast_df.columns)\n",
    "# Extract main information in this case is the title and text\n",
    "titles = podcast_df['title']\n",
    "text = podcast_df['text']  \n",
    "\n",
    "# View texxt\n",
    "print(text.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c564482a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Karen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Karen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Karen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary resources from NLTK for preprocessing\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77293a8",
   "metadata": {},
   "source": [
    "### Step 3: Text Preprocessing\n",
    "\n",
    "You know what to do ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bdc708eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    part mit course artificial general intelligenc...\n",
      "1    part mit course artificial general intelligenc...\n",
      "2    studied human mind cognition language vision e...\n",
      "3    difference biological neural network artificia...\n",
      "4    following conversation vladimir vapnik co inve...\n",
      "Name: processed_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # convert lowercase\n",
    "    text = text.lower()\n",
    "    # remove special carathers and numbers\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\d+', ' ', text)\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lematización\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    # Join tokens into a single chain\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing  to text\n",
    "podcast_df['processed_text'] = podcast_df['text'].apply(preprocess_text)\n",
    "\n",
    "# Show some processed texts\n",
    "print(podcast_df['processed_text'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fe859f",
   "metadata": {},
   "source": [
    "###  Step 4: Vector Space Representation - TF-IDF\n",
    "\n",
    "Create TF-IDF vector representations of the transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db0b0305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TF-IDF matrix: (319, 41079)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Inicializar el vectorizador TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Ajustar y transformar las transcripciones procesadas\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(podcast_df['processed_text'])\n",
    "\n",
    "# Mostrar la forma de la matriz TF-IDF\n",
    "print(\"Shape of TF-IDF matrix:\", tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d8c5ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.42.3)\n",
      "Requirement already satisfied: torch in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.13.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.13.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\karen\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5338985",
   "metadata": {},
   "source": [
    "### Step 5: Vector Space Representation - BERT\n",
    "\n",
    "Create BERT vector representations of the transcripts using a pre-trained BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8d02a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of BERT embeddings: (768,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cargar el tokenizer y el modelo de BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Función para obtener las representaciones BERT\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "# Aplicar la función de embeddings BERT a las transcripciones procesadas\n",
    "podcast_df['bert_embeddings'] = podcast_df['processed_text'].apply(get_bert_embeddings)\n",
    "\n",
    "# Mostrar la forma de las representaciones BERT\n",
    "print(\"Shape of BERT embeddings:\", podcast_df['bert_embeddings'].iloc[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892930db",
   "metadata": {},
   "source": [
    "### Step 6: Query Processing\n",
    "\n",
    "Define a function to process the query and compute similarity scores using both TF-IDF and BERT embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15558a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para procesar la consulta\n",
    "def process_query(query, podcast_df, tfidf_vectorizer, tfidf_matrix):\n",
    "    # Preprocesar la consulta\n",
    "    query_processed = preprocess_text(query)\n",
    "\n",
    "    # Vectorizar la consulta utilizando TF-IDF\n",
    "    query_tfidf = tfidf_vectorizer.transform([query_processed])\n",
    "    \n",
    "    # Calcular la similitud de coseno para TF-IDF\n",
    "    tfidf_similarities = cosine_similarity(query_tfidf, tfidf_matrix).flatten()\n",
    "\n",
    "    # Vectorizar la consulta utilizando BERT\n",
    "    query_bert_embedding = get_bert_embeddings(query_processed).reshape(1, -1)\n",
    "    \n",
    "    # Calcular la similitud de coseno para BERT\n",
    "    bert_embeddings = np.vstack(podcast_df['bert_embeddings'].values)\n",
    "    bert_similarities = cosine_similarity(query_bert_embedding, bert_embeddings).flatten()\n",
    "\n",
    "    # Crear un DataFrame con los resultados\n",
    "    results_df = podcast_df.copy()\n",
    "    results_df['tfidf_similarity'] = tfidf_similarities\n",
    "    results_df['bert_similarity'] = bert_similarities\n",
    "\n",
    "    # Ordenar los resultados por la similitud más alta\n",
    "    results_df = results_df.sort_values(by=['tfidf_similarity', 'bert_similarity'], ascending=False)\n",
    "\n",
    "    return results_df[['title', 'tfidf_similarity', 'bert_similarity', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "540326b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query is: following\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tfidf_similarity</th>\n",
       "      <th>bert_similarity</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Vsauce</td>\n",
       "      <td>0.019918</td>\n",
       "      <td>0.152706</td>\n",
       "      <td>The following is a conversation with Michael S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>String Theory</td>\n",
       "      <td>0.015930</td>\n",
       "      <td>0.137052</td>\n",
       "      <td>The following is a conversation with Kamran Va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>iRobot</td>\n",
       "      <td>0.013856</td>\n",
       "      <td>0.165819</td>\n",
       "      <td>The following is a conversation with Colin Ang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Physics of Consciousness and the Infinite Univ...</td>\n",
       "      <td>0.013447</td>\n",
       "      <td>0.148179</td>\n",
       "      <td>The following is a conversation with Roger Pen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Chess, Deep Blue, AI, and Putin</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.147074</td>\n",
       "      <td>The following is a conversation with Gary Kasp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  tfidf_similarity  \\\n",
       "58                                              Vsauce          0.019918   \n",
       "203                                      String Theory          0.015930   \n",
       "39                                              iRobot          0.013856   \n",
       "85   Physics of Consciousness and the Infinite Univ...          0.013447   \n",
       "46                     Chess, Deep Blue, AI, and Putin          0.011628   \n",
       "\n",
       "     bert_similarity                                               text  \n",
       "58          0.152706  The following is a conversation with Michael S...  \n",
       "203         0.137052  The following is a conversation with Kamran Va...  \n",
       "39          0.165819  The following is a conversation with Colin Ang...  \n",
       "85          0.148179  The following is a conversation with Roger Pen...  \n",
       "46          0.147074  The following is a conversation with Gary Kasp...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solicitar la entrada del usuario para la consulta\n",
    "query = input(\"Ingrese su consulta: \")\n",
    "\n",
    "# Procesar la consulta del usuario\n",
    "results = process_query(query, podcast_df, tfidf_vectorizer, tfidf_matrix)\n",
    "\n",
    "# Mostrar los 5 primeros resultados\n",
    "print(\"Query is:\",query)\n",
    "results.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f22d139",
   "metadata": {},
   "source": [
    "### Step 7: Retrieve and Compare Results\n",
    "\n",
    "Define a function to retrieve the top results based on similarity scores for both TF-IDF and BERT representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f68203a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query is: following\n",
      "\n",
      "Top TF-IDF Results:\n",
      "Title: Vsauce\n",
      "TF-IDF Similarity: 0.019917631536103875\n",
      "Transcript Excerpt: The following is a conversation with Michael Stevens, the creator of Vsauce, one of the most popular educational YouTube channels in the world with over 15 million subscribers and over 1.7 billion vie...\n",
      "\n",
      "\n",
      "Title: String Theory\n",
      "TF-IDF Similarity: 0.01593006918749203\n",
      "Transcript Excerpt: The following is a conversation with Kamran Valfa, a theoretical physicist at Harvard specializing in string theory. He is the winner of the 2017 Breakthrough Prize in Fundamental Physics, which is th...\n",
      "\n",
      "\n",
      "Title: iRobot\n",
      "TF-IDF Similarity: 0.013856277430207535\n",
      "Transcript Excerpt: The following is a conversation with Colin Angle. He's the CEO and co founder of iRobot, a robotics company that for 29 years has been creating robots that operate successfully in the real world. Not ...\n",
      "\n",
      "\n",
      "Title: Physics of Consciousness and the Infinite Universe\n",
      "TF-IDF Similarity: 0.013446839690867485\n",
      "Transcript Excerpt: The following is a conversation with Roger Penrose, physicist, mathematician, and philosopher at University of Oxford. He has made fundamental contributions in many disciplines from the mathematical p...\n",
      "\n",
      "\n",
      "Title: Chess, Deep Blue, AI, and Putin\n",
      "TF-IDF Similarity: 0.01162760134261118\n",
      "Transcript Excerpt: The following is a conversation with Gary Kasparov. He's considered by many to be the greatest chess player of all time. From 1986 until his retirement in 2005, he dominated the chess world, ranking w...\n",
      "\n",
      "\n",
      "\n",
      "Top BERT Results:\n",
      "Title: Tesla Autopilot\n",
      "BERT Similarity: 0.17409609258174896\n",
      "Transcript Excerpt: The following is a conversation with Elon Musk. He's the CEO of Tesla, SpaceX, Neuralink, and a cofounder of several other companies. This conversation is part of the Artificial Intelligence podcast. ...\n",
      "\n",
      "\n",
      "Title: Generative Adversarial Networks (GANs)\n",
      "BERT Similarity: 0.1721705198287964\n",
      "Transcript Excerpt: The following is a conversation with Ian Goodfellow. He's the author of the popular textbook on deep learning simply titled Deep Learning. He coined the term of Generative Adversarial Networks, otherw...\n",
      "\n",
      "\n",
      "Title: Computing, Interactive AI, and Race in America\n",
      "BERT Similarity: 0.17134657502174377\n",
      "Transcript Excerpt: The following is a conversation with Charles Isbell, Dean of the College of Computing at Georgia Tech, a researcher and educator in the field of artificial intelligence, and someone who deeply thinks ...\n",
      "\n",
      "\n",
      "Title: YouTube Algorithm\n",
      "BERT Similarity: 0.17112040519714355\n",
      "Transcript Excerpt: The following is a conversation with Christos Goudreau, Vice President of Engineering at Google and Head of Search and Discovery at YouTube, also known as the YouTube Algorithm. YouTube has approximat...\n",
      "\n",
      "\n",
      "Title: Algorithms, TeX, Life, and The Art of Computer Programming\n",
      "BERT Similarity: 0.17052440345287323\n",
      "Transcript Excerpt: The following is a conversation with Donald Knuth, one of the greatest and most impactful computer scientists and mathematicians ever. He's the recipient of the 1974 Turing Award, considered the Nobel...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Función para recuperar y comparar los mejores resultados\n",
    "def retrieve_and_compare_results(query, podcast_df, tfidf_vectorizer, tfidf_matrix, top_n=5):\n",
    "    # Procesar la consulta\n",
    "    results_df = process_query(query, podcast_df, tfidf_vectorizer, tfidf_matrix)\n",
    "\n",
    "    # Ordenar los resultados por similitud de TF-IDF y recuperar los top N\n",
    "    top_tfidf_results = results_df.sort_values(by='tfidf_similarity', ascending=False).head(top_n)\n",
    "\n",
    "    # Ordenar los resultados por similitud de BERT y recuperar los top N\n",
    "    top_bert_results = results_df.sort_values(by='bert_similarity', ascending=False).head(top_n)\n",
    "\n",
    "    return top_tfidf_results, top_bert_results\n",
    "\n",
    "# Recuperar y comparar los resultados principales utilizando la consulta del usuario\n",
    "top_tfidf_results, top_bert_results = retrieve_and_compare_results(query, podcast_df, tfidf_vectorizer, tfidf_matrix, top_n=5)\n",
    "\n",
    "print(\"Query is:\",query)\n",
    "# Mostrar los resultados principales para TF-IDF\n",
    "print(\"\\nTop TF-IDF Results:\")\n",
    "for idx, row in top_tfidf_results.iterrows():\n",
    "    print(f\"Title: {row['title']}\")\n",
    "    print(f\"TF-IDF Similarity: {row['tfidf_similarity']}\")\n",
    "    print(f\"Transcript Excerpt: {row['text'][:200]}...\")  # Mostrar los primeros 200 caracteres de la transcripción\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Mostrar los resultados principales para BERT\n",
    "print(\"\\nTop BERT Results:\")\n",
    "for idx, row in top_bert_results.iterrows():\n",
    "    print(f\"Title: {row['title']}\")\n",
    "    print(f\"BERT Similarity: {row['bert_similarity']}\")\n",
    "    print(f\"Transcript Excerpt: {row['text'][:200]}...\")  # Mostrar los primeros 200 caracteres de la transcripción\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401d723b",
   "metadata": {},
   "source": [
    "### Step 8: Test the IR System\n",
    "\n",
    "Test the system with a sample query.\n",
    "\n",
    "Retrieve and display the top results using both TF-IDF and BERT representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81492a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query test is: child\n",
      "\n",
      "Top TF-IDF Results:\n",
      "Title: Computer Vision\n",
      "TF-IDF Similarity: 0.12085287681942182\n",
      "Transcript Excerpt: The following is a conversation with Jitendra Malik, a professor at Berkeley and one of the seminal figures in the field of computer vision, the kind before the deep learning revolution and the kind a...\n",
      "\n",
      "\n",
      "Title: Yaron Brook and Yoram Hazony\n",
      "TF-IDF Similarity: 0.06513779225115413\n",
      "Transcript Excerpt: The following is a conversation with Yoram Brook and Yoram Hazoni. This is Yoram's third time on this podcast and Yoram's first time. Yoram Brook is an Objectivist Philosopher, Chairman of the Ayn Ran...\n",
      "\n",
      "\n",
      "Title: Hunger, War, and Human Suffering\n",
      "TF-IDF Similarity: 0.05843336538347112\n",
      "Transcript Excerpt: we would come up to these rafts and these boats that were in really dire shape and people would be pushed off and people would jump off and people would fall into the water and some of them couldn't s...\n",
      "\n",
      "\n",
      "Title: Artificial Consciousness and the Nature of Reality\n",
      "TF-IDF Similarity: 0.04922064845752266\n",
      "Transcript Excerpt: The following is a conversation with Yosha Bach, VP of Research at the AI Foundation, with a history of research positions at MIT and Harvard. Yosha is one of the most unique and brilliant people in t...\n",
      "\n",
      "\n",
      "Title: Race, Racism, Identity Politics, and Cancel Culture\n",
      "TF-IDF Similarity: 0.04777534753074181\n",
      "Transcript Excerpt: I hate affirmative action. I don't just disagree with it. I don't just think it's against the 14th Amendment. I hate it. The hatred comes from an understanding that it is a bandaid, that it is a subst...\n",
      "\n",
      "\n",
      "\n",
      "Top BERT Results:\n",
      "Title: Race, Racism, Identity Politics, and Cancel Culture\n",
      "BERT Similarity: 0.21039777994155884\n",
      "Transcript Excerpt: I hate affirmative action. I don't just disagree with it. I don't just think it's against the 14th Amendment. I hate it. The hatred comes from an understanding that it is a bandaid, that it is a subst...\n",
      "\n",
      "\n",
      "Title: iRobot\n",
      "BERT Similarity: 0.20068936049938202\n",
      "Transcript Excerpt: The following is a conversation with Colin Angle. He's the CEO and co founder of iRobot, a robotics company that for 29 years has been creating robots that operate successfully in the real world. Not ...\n",
      "\n",
      "\n",
      "Title: Stalin, Putin, and the Nature of Power\n",
      "BERT Similarity: 0.20057770609855652\n",
      "Transcript Excerpt: The following is a conversation with Stephen Kotkin, a professor of history at Princeton University and one of the great historians of our time, specializing in Russian and Soviet history. He has writ...\n",
      "\n",
      "\n",
      "Title: Tesla Autopilot\n",
      "BERT Similarity: 0.19893589615821838\n",
      "Transcript Excerpt: The following is a conversation with Elon Musk. He's the CEO of Tesla, SpaceX, Neuralink, and a cofounder of several other companies. This conversation is part of the Artificial Intelligence podcast. ...\n",
      "\n",
      "\n",
      "Title: Extending the Human Lifespan Beyond 100 Years\n",
      "BERT Similarity: 0.19809666275978088\n",
      "Transcript Excerpt: The following is a conversation with David Sinclair. He's a professor in the Department of Genetics at Harvard and co director of the Paul F. Glenn Center for the Biology of Aging at Harvard Medical S...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir la consulta de prueba\n",
    "test_query = \"child\"\n",
    "\n",
    "# Recuperar y comparar los resultados principales utilizando la consulta de prueba\n",
    "top_tfidf_results, top_bert_results = retrieve_and_compare_results(test_query, podcast_df, tfidf_vectorizer, tfidf_matrix, top_n=5)\n",
    "\n",
    "print(\"Query test is:\",test_query)\n",
    "# Mostrar los resultados principales para TF-IDF\n",
    "print(\"\\nTop TF-IDF Results:\")\n",
    "for idx, row in top_tfidf_results.iterrows():\n",
    "    print(f\"Title: {row['title']}\")\n",
    "    print(f\"TF-IDF Similarity: {row['tfidf_similarity']}\")\n",
    "    print(f\"Transcript Excerpt: {row['text'][:200]}...\")  # Mostrar los primeros 200 caracteres de la transcripción\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Mostrar los resultados principales para BERT\n",
    "print(\"\\nTop BERT Results:\")\n",
    "for idx, row in top_bert_results.iterrows():\n",
    "    print(f\"Title: {row['title']}\")\n",
    "    print(f\"BERT Similarity: {row['bert_similarity']}\")\n",
    "    print(f\"Transcript Excerpt: {row['text'][:200]}...\")  # Mostrar los primeros 200 caracteres de la transcripción\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff10b1e1",
   "metadata": {},
   "source": [
    "### Step 9: Compare Results\n",
    "\n",
    "Analyze and compare the results obtained from TF-IDF and BERT representations.\n",
    "\n",
    "Discuss the differences, strengths, and weaknesses of each method based on the retrieval results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc912bfa",
   "metadata": {},
   "source": [
    "TF-IDF \n",
    "\n",
    "Ventaja: Los resultados suelen ser relevantes cuando las palabras clave de la consulta aparecen exactamente en el texto.\n",
    "Desventaja: Puede incluir resultados menos relevantes si las palabras clave son comunes en diferentes contextos.\n",
    "\n",
    "BERT\n",
    "\n",
    "Ventaja: Captura mejor el contexto y la semántica, proporcionando resultados más precisos y relevantes.\n",
    "Desventaja: Los resultados pueden variar y ser menos predecibles, pero suelen tener una comprensión más profunda del tema.\n",
    "\n",
    "\n",
    "Eficiencia Computacional\n",
    "\n",
    "\n",
    "TF-IDF: Es más rápido y eficiente computacionalmente. Adecuado para sistemas con recursos limitados.\n",
    "\n",
    "BERT: Requiere más recursos de procesamiento y memoria, pero ofrece una mayor precisión en la recuperación de información."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
