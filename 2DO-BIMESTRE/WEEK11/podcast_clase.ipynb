{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Karen\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Necessary libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      As part of MIT course 6S099, Artificial Genera...\n",
      "1      As part of MIT course 6S099 on artificial gene...\n",
      "2      You've studied the human mind, cognition, lang...\n",
      "3      What difference between biological neural netw...\n",
      "4      The following is a conversation with Vladimir ...\n",
      "                             ...                        \n",
      "314    By the time he gets to 2045, we'll be able to ...\n",
      "315    there's a broader question here, right? As we ...\n",
      "316    Once this whole thing falls apart and we are c...\n",
      "317    you could be the seventh best player in the wh...\n",
      "318    turns out that if you train a planarian and th...\n",
      "Name: text, Length: 319, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "podcast_df = pd.read_csv('../WEEK11/archive/podcastdata_dataset.csv')\n",
    "# Mostrar los nombres de las columnas\n",
    "# print(podcast_df.columns)\n",
    "# Extract main information in this case is the title and text\n",
    "# titles = podcast_df['title']\n",
    "corpus = podcast_df['text']  \n",
    "\n",
    "# View texxt\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Karen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'word'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m corpus_nopunct\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m corpus:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# print(len(doc.split()))\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mcorpus_nopunct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword\u001b[49m\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mtranslate(\u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m.\u001b[39mmaketrans(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,string\u001b[38;5;241m.\u001b[39mpunctuation))\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# corpus_nopunct.append(corpus_sinPuntuacion)\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'word'"
     ]
    }
   ],
   "source": [
    "import string\n",
    "#arreglo para almacenar el txt limpio\n",
    "corpus_nopunct=[]\n",
    "for word in corpus:\n",
    "    # print(len(doc.split()))\n",
    "    corpus_nopunct.word.lower().translate(str.maketrans('','',string.punctuation))\n",
    "    # corpus_nopunct.append(corpus_sinPuntuacion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n"
     ]
    }
   ],
   "source": [
    "print(corpus_nopunct[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    }
   ],
   "source": [
    "stopw = set(stopwords.words('english'))\n",
    "print(len(stopw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_norep = []\n",
    "for doc in corpus_nopunct:\n",
    "    corpus_norep.append(set(doc.split(' ')) )\n",
    "    \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'i'}, {'d'}]\n"
     ]
    }
   ],
   "source": [
    "print(corpus_norep[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
